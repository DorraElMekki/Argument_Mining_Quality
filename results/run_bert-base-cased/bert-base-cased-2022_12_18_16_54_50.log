device: cuda
df.head(2)    Unnamed: 0.1  Unnamed: 0  ann_id         ann_file_id          ann_file argQ_id  ... nbr_CLAIM-Opinion(view) nbr_CLAIM-Fact nbr_CLAIM-Value  nbr_CLAIM-Other  nbr_CLAIM-Policy                          combined_textual_features
0             0           0       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ0  ...                       1              0               0                0                 0   [cl_text] So in terms of the deceleration, we...
1             1           1       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ1  ...                       1              0               0                0                 0   [cl_text] So I think we are experiencing dece...

[2 rows x 50 columns]
possible_labels for STRONG:[0 1 2]
label_dict for STRONG:{0: 0, 1: 1, 2: 2}
claim_label_dict for claim_label:{'CLAIM-Opinion(view)': 0, 'CLAIM-Fact': 1, 'CLAIM-Value': 2, 'CLAIM-Other': 3, 'CLAIM-Policy': 4}
dataset:DatasetDict({
    train: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1092
    })
    test: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1092
    })
})
example from the dataset:{'label': 2, 'extra_data': [3, 0, 0, 0, 0], 'text': " [cl_text] So in terms of the deceleration, we continue to expect deceleration into 2020, but it would be, we believe, more moderated and the reasons for that, that we expect the deceleration. [/cl_text]  [pr_text] We do continue to see these ad targeting related headwinds, which have been playing out slowly, but we think are still in front of us. [/pr_text]  [pr_text] The majority of potential signal loss on targeting is still in front of us. [/pr_text]  [pr_text] And that's the three factors that I cited, the regulatory landscape, potential platform changes and then the adoption of our own products like OFA that we're just rolling out now. [/pr_text] "}
tokenized_datasets:DatasetDict({
    train: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1092
    })
    test: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1092
    })
})
{'accuracy': 0.7087912087912088}
{'matthews_correlation': 0.3510839087582501}
{'pearsonr': 0.40752899949472315}
{'precision': array([0.22916667, 0.78744277, 0.54859967])}
{'precision': 0.7087912087912088}
{'precision': 0.5217363700772196}
{'precision': 0.6926750301672893}
{'recall': array([0.07971014, 0.80159787, 0.61213235])}
{'recall': 0.7087912087912088}
{'recall': 0.49781345579201214}
{'recall': 0.7087912087912088}
{'spearmanr': 0.41970990294564037}
{'f1': array([0.11827957, 0.79445727, 0.57862728])}
{'f1': 0.7087912087912089}
{'f1': 0.4971213751149353}
{'f1': 0.6979719084685416}
{'accuracy': 0.7298534798534798}
{'matthews_correlation': 0.47396201869901927}
{'pearsonr': 0.5377339711416135}
{'precision': array([0.21276596, 0.80214724, 0.67175573])}
{'precision': 0.7298534798534798}
{'precision': 0.5622229739671506}
{'precision': 0.7241886177031321}
{'recall': array([0.14492754, 0.76686217, 0.77419355])}
{'recall': 0.7298534798534798}
{'recall': 0.5619944182356524}
{'recall': 0.7298534798534798}
{'spearmanr': 0.5636757029883414}
{'f1': array([0.17241379, 0.78410795, 0.71934605])}
{'f1': 0.7298534798534798}
{'f1': 0.5586225960589188}
{'f1': 0.7252336754938996}
df_result.csv file exists
   metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train                        metric_precision_none_train  metric_precision_micro_train  ...    token  fold_id cv       lr  batch_size
0               0.708791                          0.351084               0.407529  [0.22916666666666666, 0.7874427730542839, 0.54...                      0.708791  ...  special        0  2  0.00002           8

[1 rows x 60 columns]
df.head(2)    Unnamed: 0.1  Unnamed: 0  ann_id         ann_file_id          ann_file argQ_id  ... nbr_CLAIM-Opinion(view) nbr_CLAIM-Fact nbr_CLAIM-Value  nbr_CLAIM-Other  nbr_CLAIM-Policy                          combined_textual_features
0             0           0       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ0  ...                       1              0               0                0                 0   [cl_text] So in terms of the deceleration, we...
1             1           1       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ1  ...                       1              0               0                0                 0   [cl_text] So I think we are experiencing dece...

[2 rows x 50 columns]
possible_labels for STRONG:[0 1 2]
label_dict for STRONG:{0: 0, 1: 1, 2: 2}
claim_label_dict for claim_label:{'CLAIM-Opinion(view)': 0, 'CLAIM-Fact': 1, 'CLAIM-Value': 2, 'CLAIM-Other': 3, 'CLAIM-Policy': 4}
dataset:DatasetDict({
    train: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1091
    })
    test: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1093
    })
})
example from the dataset:{'label': 1, 'extra_data': [2, 0, 0, 0, 0], 'text': " [cl_text] So I think we are experiencing deceleration from that perspective. [/cl_text]  [pr_text] Obviously, we're lapping what's been good performance in 2019 where we've made a lot of product improvements and growing off a large base. [/pr_text]  [pr_text] The specific sort of high level of deceleration going into Q4, we're signing the specific optimizations that we're lapping in Q4, which were more significant. [/pr_text] "}
tokenized_datasets:DatasetDict({
    train: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1091
    })
    test: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1093
    })
})
{'accuracy': 0.7286892758936755}
{'matthews_correlation': 0.4049076943718713}
{'pearsonr': 0.4532134805736455}
{'precision': array([0.19230769, 0.78590078, 0.61057692])}
{'precision': 0.7286892758936755}
{'precision': 0.5295951328914775}
{'precision': 0.7007299240678861}
{'recall': array([0.03571429, 0.82692308, 0.65017065])}
{'recall': 0.7286892758936755}
{'recall': 0.5042693370338421}
{'recall': 0.7286892758936755}
{'spearmanr': 0.4693665816133912}
{'f1': array([0.06024096, 0.80589023, 0.62975207])}
{'f1': 0.7286892758936755}
{'f1': 0.4986277525160328}
{'f1': 0.7107445540951584}
{'accuracy': 0.7319304666056725}
{'matthews_correlation': 0.47617850844449877}
{'pearsonr': 0.5528337334380057}
{'precision': array([0.27941176, 0.8173516 , 0.66304348])}
{'precision': 0.7319304666056725}
{'precision': 0.5866022803800893}
{'precision': 0.7387070354581949}
{'recall': array([0.27941176, 0.76170213, 0.7625    ])}
{'recall': 0.7319304666056725}
{'recall': 0.6012046307884856}
{'recall': 0.7319304666056725}
{'spearmanr': 0.5717851242689216}
{'f1': array([0.27941176, 0.78854626, 0.70930233])}
{'f1': 0.7319304666056724}
{'f1': 0.5924201152646286}
{'f1': 0.7336704980038473}
df_result.csv file exists
   metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train                        metric_precision_none_train  metric_precision_micro_train  ...    token  fold_id cv       lr  batch_size
0               0.728689                          0.404908               0.453213  [0.19230769230769232, 0.7859007832898173, 0.61...                      0.728689  ...  special        1  2  0.00002           8

[1 rows x 60 columns]
df_result.csv file exists
   Unnamed: 0  metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train  metric_precision_micro_train  metric_precision_macro_train  ...  support_test  fold_id   cv       lr  batch_size  cv_calculation
0         5.5                0.71874                          0.377996               0.430371                       0.71874                      0.525666  ...        1092.5      0.5  2.0  0.00002         8.0            mean

[1 rows x 39 columns]
df_result.csv file exists
   Unnamed: 0  metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train  metric_precision_micro_train  metric_precision_macro_train  ...  support_test   fold_id   cv   lr  batch_size  cv_calculation
0    0.707107                0.01407                          0.038059               0.032304                       0.01407                      0.005557  ...      0.707107  0.707107  0.0  0.0         0.0             std

[1 rows x 39 columns]
df_result.csv file exists
   Unnamed: 0  metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train  metric_precision_micro_train  metric_precision_macro_train  ...  support_test  fold_id   cv   lr  batch_size  cv_calculation
0         0.5               0.009949                          0.026912               0.022842                      0.009949                      0.003929  ...           0.5      0.5  0.0  0.0         0.0             sem

[1 rows x 39 columns]
df.head(2)    Unnamed: 0.1  Unnamed: 0  ann_id         ann_file_id          ann_file argQ_id  ... nbr_CLAIM-Opinion(view) nbr_CLAIM-Fact nbr_CLAIM-Value  nbr_CLAIM-Other  nbr_CLAIM-Policy                          combined_textual_features
0             0           0       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ0  ...                       1              0               0                0                 0   [cl_text] So in terms of the deceleration, we...
1             1           1       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ1  ...                       1              0               0                0                 0   [cl_text] So I think we are experiencing dece...

[2 rows x 50 columns]
possible_labels for STRONG:[0 1 2]
label_dict for STRONG:{0: 0, 1: 1, 2: 2}
claim_label_dict for claim_label:{'CLAIM-Opinion(view)': 0, 'CLAIM-Fact': 1, 'CLAIM-Value': 2, 'CLAIM-Other': 3, 'CLAIM-Policy': 4}
dataset:DatasetDict({
    train: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1094
    })
    test: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1090
    })
})
example from the dataset:{'label': 1, 'extra_data': [2, 0, 0, 0, 0], 'text': " [cl_text] So I think we are experiencing deceleration from that perspective. [/cl_text]  [pr_text] Obviously, we're lapping what's been good performance in 2019 where we've made a lot of product improvements and growing off a large base. [/pr_text]  [pr_text] The specific sort of high level of deceleration going into Q4, we're signing the specific optimizations that we're lapping in Q4, which were more significant. [/pr_text] "}
tokenized_datasets:DatasetDict({
    train: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1094
    })
    test: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1090
    })
})
{'accuracy': 0.7230347349177331}
{'matthews_correlation': 0.4460022860565983}
{'pearsonr': 0.5225511735902144}
{'precision': array([0.33152174, 0.80282376, 0.63505747])}
{'precision': 0.7230347349177331}
{'precision': 0.5898009896382544}
{'precision': 0.7239893616484676}
{'recall': array([0.27853881, 0.77200375, 0.71521036])}
{'recall': 0.7230347349177331}
{'recall': 0.5885843046969318}
{'recall': 0.7230347349177331}
{'spearmanr': 0.5354100442537627}
{'f1': array([0.30272953, 0.78711217, 0.67275495])}
{'f1': 0.723034734917733}
{'f1': 0.5875322157004127}
{'f1': 0.7224903112160768}
{'accuracy': 0.6990825688073394}
{'matthews_correlation': 0.44202654493609006}
{'pearsonr': 0.5325977354590712}
{'precision': array([0.18348624, 0.83112583, 0.63660477])}
{'precision': 0.6990825688073394}
{'precision': 0.5504056136274963}
{'precision': 0.7382533750621815}
{'recall': array([0.30769231, 0.6962552 , 0.78947368])}
{'recall': 0.6990825688073394}
{'recall': 0.597807064337468}
{'recall': 0.6990825688073394}
{'spearmanr': 0.5583011473427245}
{'f1': array([0.22988506, 0.75773585, 0.70484581])}
{'f1': 0.6990825688073394}
{'f1': 0.5641555738352806}
{'f1': 0.7115075262924291}
df_result.csv file exists
   metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train                        metric_precision_none_train  metric_precision_micro_train  ...    token  fold_id cv       lr  batch_size
0               0.723035                          0.446002               0.522551  [0.33152173913043476, 0.802823758519961, 0.635...                      0.723035  ...  special        0  2  0.00002           8

[1 rows x 63 columns]
df.head(2)    Unnamed: 0.1  Unnamed: 0  ann_id         ann_file_id          ann_file argQ_id  ... nbr_CLAIM-Opinion(view) nbr_CLAIM-Fact nbr_CLAIM-Value  nbr_CLAIM-Other  nbr_CLAIM-Policy                          combined_textual_features
0             0           0       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ0  ...                       1              0               0                0                 0   [cl_text] So in terms of the deceleration, we...
1             1           1       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ1  ...                       1              0               0                0                 0   [cl_text] So I think we are experiencing dece...

[2 rows x 50 columns]
possible_labels for STRONG:[0 1 2]
label_dict for STRONG:{0: 0, 1: 1, 2: 2}
claim_label_dict for claim_label:{'CLAIM-Opinion(view)': 0, 'CLAIM-Fact': 1, 'CLAIM-Value': 2, 'CLAIM-Other': 3, 'CLAIM-Policy': 4}
dataset:DatasetDict({
    train: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1093
    })
    test: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1091
    })
})
example from the dataset:{'label': 2, 'extra_data': [3, 0, 0, 0, 0], 'text': " [cl_text] So in terms of the deceleration, we continue to expect deceleration into 2020, but it would be, we believe, more moderated and the reasons for that, that we expect the deceleration. [/cl_text]  [pr_text] We do continue to see these ad targeting related headwinds, which have been playing out slowly, but we think are still in front of us. [/pr_text]  [pr_text] The majority of potential signal loss on targeting is still in front of us. [/pr_text]  [pr_text] And that's the three factors that I cited, the regulatory landscape, potential platform changes and then the adoption of our own products like OFA that we're just rolling out now. [/pr_text] "}
tokenized_datasets:DatasetDict({
    train: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1093
    })
    test: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1091
    })
})
{'accuracy': 0.7151570600792925}
{'matthews_correlation': 0.4297491359011926}
{'pearsonr': 0.4765786583043394}
{'precision': array([0.25396825, 0.80973451, 0.6155303 ])}
{'precision': 0.7151570600792925}
{'precision': 0.5597443567576311}
{'precision': 0.7207879497176229}
{'recall': array([0.23529412, 0.7635605 , 0.708061  ])}
{'recall': 0.7151570600792925}
{'recall': 0.5689718735070395}
{'recall': 0.7151570600792925}
{'spearmanr': 0.495886590200205}
{'f1': array([0.24427481, 0.78596994, 0.6585613 ])}
{'f1': 0.7151570600792925}
{'f1': 0.5629353471985697}
{'f1': 0.7165991102846472}
{'accuracy': 0.6727772685609532}
{'matthews_correlation': 0.4166015897312695}
{'pearsonr': 0.5530286938021001}
{'precision': array([0.18343195, 0.80782313, 0.68263473])}
{'precision': 0.6727772685609532}
{'precision': 0.5579632708177816}
{'precision': 0.7325342009601776}
{'recall': array([0.44285714, 0.66526611, 0.74267101])}
{'recall': 0.6727772685609532}
{'recall': 0.616931419690569}
{'recall': 0.6727772685609532}
{'spearmanr': 0.5731362131168055}
{'f1': array([0.25941423, 0.7296467 , 0.71138846])}
{'f1': 0.6727772685609532}
{'f1': 0.566816459622759}
{'f1': 0.6943382159501534}
df_result.csv file exists
   metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train                        metric_precision_none_train  metric_precision_micro_train  ...    token  fold_id cv       lr  batch_size
0               0.715157                          0.429749               0.476579  [0.25396825396825395, 0.8097345132743363, 0.61...                      0.715157  ...  special        1  2  0.00002           8

[1 rows x 63 columns]
df_result.csv file exists
   Unnamed: 0  metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train  metric_precision_micro_train  metric_precision_macro_train  ...  fold_id   cv       lr  batch_size  loss_train_epoch_3  cv_calculation
0        10.5               0.719096                          0.437876               0.499565                      0.719096                      0.574773  ...      0.5  2.0  0.00002         8.0            2.408201            mean

[1 rows x 40 columns]
df_result.csv file exists
   Unnamed: 0  metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train  metric_precision_micro_train  metric_precision_macro_train  ...   fold_id   cv   lr  batch_size  loss_train_epoch_3  cv_calculation
0    0.707107                0.00557                          0.011493               0.032507                       0.00557                      0.021253  ...  0.707107  0.0  0.0         0.0            0.046172             std

[1 rows x 40 columns]
df_result.csv file exists
   Unnamed: 0  metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train  metric_precision_micro_train  metric_precision_macro_train  ...  fold_id   cv   lr  batch_size  loss_train_epoch_3  cv_calculation
0         0.5               0.003939                          0.008127               0.022986                      0.003939                      0.015028  ...      0.5  0.0  0.0         0.0            0.032649             sem

[1 rows x 40 columns]
df.head(2)    Unnamed: 0.1  Unnamed: 0  ann_id         ann_file_id          ann_file argQ_id  ... nbr_CLAIM-Opinion(view) nbr_CLAIM-Fact nbr_CLAIM-Value  nbr_CLAIM-Other  nbr_CLAIM-Policy                          combined_textual_features
0             0           0       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ0  ...                       1              0               0                0                 0   [cl_text] So in terms of the deceleration, we...
1             1           1       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ1  ...                       1              0               0                0                 0   [cl_text] So I think we are experiencing dece...

[2 rows x 50 columns]
possible_labels for STRONG:[0 1 2]
label_dict for STRONG:{0: 0, 1: 1, 2: 2}
claim_label_dict for claim_label:{'CLAIM-Opinion(view)': 0, 'CLAIM-Fact': 1, 'CLAIM-Value': 2, 'CLAIM-Other': 3, 'CLAIM-Policy': 4}
dataset:DatasetDict({
    train: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1089
    })
    test: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1095
    })
})
example from the dataset:{'label': 1, 'extra_data': [1, 0, 0, 0, 0], 'text': " [cl_text] So it's a great benefit for sellers, and it only works if it's a great benefit for customers on the other side. [/cl_text]  [pr_text] So, yeah, I don't have a lot to share on that today, but I think you hit on the train_test_bert_with_categorical_features point, is selection and opportunities for sellers in â€“ who are with us in different countries to reach buyers outside of their home country. [/pr_text] "}
tokenized_datasets:DatasetDict({
    train: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1089
    })
    test: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1095
    })
})
{'accuracy': 0.6831955922865014}
{'matthews_correlation': 0.4008387537431381}
{'pearsonr': 0.4905699678781531}
{'precision': array([0.22666667, 0.80878244, 0.60528194])}
{'precision': 0.6831955922865014}
{'precision': 0.5469103477555951}
{'precision': 0.716559735534113}
{'recall': array([0.375     , 0.70152355, 0.7090301 ])}
{'recall': 0.6831955922865014}
{'recall': 0.595184548680273}
{'recall': 0.6831955922865014}
{'spearmanr': 0.5058809727221129}
{'f1': array([0.28254848, 0.75134434, 0.65306122])}
{'f1': 0.6831955922865014}
{'f1': 0.5623180120644956}
{'f1': 0.6950865129214012}
{'accuracy': 0.719634703196347}
{'matthews_correlation': 0.44718084510585615}
{'pearsonr': 0.5153983642984131}
{'precision': array([0.20895522, 0.80838323, 0.65      ])}
{'precision': 0.719634703196347}
{'precision': 0.5557794858045103}
{'precision': 0.724645976907359}
{'recall': array([0.2       , 0.75949367, 0.74522293])}
{'recall': 0.719634703196347}
{'recall': 0.5682388669407938}
{'recall': 0.719634703196347}
{'spearmanr': 0.5397937841922631}
{'f1': array([0.20437956, 0.78317621, 0.69436202])}
{'f1': 0.719634703196347}
{'f1': 0.5606392648320819}
{'f1': 0.7207073347474964}
df_result.csv file exists
   metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train                        metric_precision_none_train  metric_precision_micro_train  ...    token  fold_id cv       lr  batch_size
0               0.683196                          0.400839                0.49057  [0.22666666666666666, 0.8087824351297406, 0.60...                      0.683196  ...  special        0  2  0.00002           8

[1 rows x 66 columns]
df.head(2)    Unnamed: 0.1  Unnamed: 0  ann_id         ann_file_id          ann_file argQ_id  ... nbr_CLAIM-Opinion(view) nbr_CLAIM-Fact nbr_CLAIM-Value  nbr_CLAIM-Other  nbr_CLAIM-Policy                          combined_textual_features
0             0           0       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ0  ...                       1              0               0                0                 0   [cl_text] So in terms of the deceleration, we...
1             1           1       7  FB_Q3_2019_17751_7  FB_Q3_2019_17751   ArgQ1  ...                       1              0               0                0                 0   [cl_text] So I think we are experiencing dece...

[2 rows x 50 columns]
possible_labels for STRONG:[0 1 2]
label_dict for STRONG:{0: 0, 1: 1, 2: 2}
claim_label_dict for claim_label:{'CLAIM-Opinion(view)': 0, 'CLAIM-Fact': 1, 'CLAIM-Value': 2, 'CLAIM-Other': 3, 'CLAIM-Policy': 4}
dataset:DatasetDict({
    train: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1090
    })
    test: Dataset({
        features: ['label', 'extra_data', 'text'],
        num_rows: 1094
    })
})
example from the dataset:{'label': 2, 'extra_data': [3, 0, 0, 0, 0], 'text': " [cl_text] So in terms of the deceleration, we continue to expect deceleration into 2020, but it would be, we believe, more moderated and the reasons for that, that we expect the deceleration. [/cl_text]  [pr_text] We do continue to see these ad targeting related headwinds, which have been playing out slowly, but we think are still in front of us. [/pr_text]  [pr_text] The majority of potential signal loss on targeting is still in front of us. [/pr_text]  [pr_text] And that's the three factors that I cited, the regulatory landscape, potential platform changes and then the adoption of our own products like OFA that we're just rolling out now. [/pr_text] "}
tokenized_datasets:DatasetDict({
    train: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1090
    })
    test: Dataset({
        features: ['labels', 'extra_data', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1094
    })
})
{'accuracy': 0.7495412844036697}
{'matthews_correlation': 0.49171490950366953}
{'pearsonr': 0.5537770316061915}
{'precision': array([0.24233129, 0.83249461, 0.69728435])}
{'precision': 0.7495412844036697}
{'precision': 0.5907034138623415}
{'precision': 0.758790134643213}
{'recall': array([0.28623188, 0.79532967, 0.74488055])}
{'recall': 0.7495412844036697}
{'recall': 0.6088140334875756}
{'recall': 0.7495412844036697}
{'spearmanr': 0.5781115788574683}
{'f1': array([0.26245847, 0.81348788, 0.72029703])}
{'f1': 0.7495412844036697}
{'f1': 0.5987477944816001}
{'f1': 0.7535558186574836}
{'accuracy': 0.720292504570384}
{'matthews_correlation': 0.4723093185873661}
{'pearsonr': 0.5473072024269384}
{'precision': array([0.29885057, 0.82664526, 0.64322917])}
{'precision': 0.720292504570384}
{'precision': 0.5895750020756075}
{'precision': 0.7397065216691057}
{'recall': array([0.37681159, 0.73049645, 0.771875  ])}
{'recall': 0.720292504570384}
{'recall': 0.6263943493678693}
{'recall': 0.720292504570384}
{'spearmanr': 0.5631601281098728}
{'f1': array([0.33333333, 0.77560241, 0.70170455])}
{'f1': 0.720292504570384}
{'f1': 0.603546762808811}
{'f1': 0.7260924619201419}
df_result.csv file exists
   metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train                        metric_precision_none_train  metric_precision_micro_train  ...    token  fold_id cv       lr  batch_size
0               0.749541                          0.491715               0.553777  [0.24233128834355827, 0.8324946081955428, 0.69...                      0.749541  ...  special        1  2  0.00002           8

[1 rows x 66 columns]
df_result.csv file exists
   Unnamed: 0  metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train  metric_precision_micro_train  metric_precision_macro_train  ...   cv       lr  batch_size  loss_train_epoch_3  loss_train_epoch_4  cv_calculation
0        15.5               0.716368                          0.446277               0.522173                      0.716368                      0.568807  ...  2.0  0.00002         8.0            2.470522            3.084131            mean

[1 rows x 41 columns]
df_result.csv file exists
   Unnamed: 0  metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train  metric_precision_micro_train  metric_precision_macro_train  ...   cv   lr  batch_size  loss_train_epoch_3  loss_train_epoch_4  cv_calculation
0    0.707107               0.046913                          0.064259               0.044694                      0.046913                      0.030966  ...  0.0  0.0         0.0            0.039959            0.074817             std

[1 rows x 41 columns]
df_result.csv file exists
   Unnamed: 0  metric_accuracy_train  metric_matthewscorrelation_train  metric_pearsonr_train  metric_precision_micro_train  metric_precision_macro_train  ...   cv   lr  batch_size  loss_train_epoch_3  loss_train_epoch_4  cv_calculation
0         0.5               0.033173                          0.045438               0.031604                      0.033173                      0.021897  ...  0.0  0.0         0.0            0.028256            0.052904             sem

[1 rows x 41 columns]
